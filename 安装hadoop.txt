http://blog.csdn.net/lnho2015/article/details/51095614
http://blog.csdn.net/sagaryu/article/details/52137989
http://www.cnblogs.com/shishanyuan/p/4701646.html

1.安装maven
2.安装autoconf automake libtool cmake
3.安装ncurses-devel
4.安装openssl-devel
5.安装gcc*
6.安装并设置protobuf
1.8报错
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-antrun-plugin:1.7:run (create-testdirs) on project hadoop-project: Execution create-testdirs of goal org.apache.maven.plugins:maven-antrun-plugin:1.7:run failed: Plugin org.apache.maven.plugins:maven-antrun-plugin:1.7 or one of its dependencies could not be resolved: Could not transfer artifact org.apache.ant:ant:jar:1.8.2 from/to central (https://repo.maven.apache.org/maven2): GET request of: org/apache/ant/ant/1.8.2/ant-1.8.2.jar from central failed: Connection reset -> [Help 1]



1.安装maven
1.1下载maven
下载地址http://maven.apache.org/

1.2解压
# tar -zxvf /..目录/apache-maven-3.3.9-bin.tar.gz -C /usr/local/maven

1.3配置
# vim /etc/profile
配置PATH路径
export MAVEN_HOME=/usr/local/maven/apache-maven-3.3.9
export PATH=$MAVEN_HOME/bin:$PATH
# source /etc/profile

1.4验证
# mvn --version
Apache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-11T00:41:47+08:00)
Maven home: /usr/local/maven/apache-maven-3.3.9
Java version: 1.7.0_79, vendor: Oracle Corporation
Java home: /usr/local/java/jdk1.7.0_79/jre
Default locale: en_US, platform encoding: UTF-8
OS name: "linux", version: "2.6.32-504.el6.i686", arch: "i386", family: "unix"

2.安装autoconf automake libtool cmake
# yum install autoconf automake libtool cmake

3.安装ncurses-devel
# yum install ncurses-devel

4.安装openssl-devel
# yum install openssl-devel

5.安装gcc*
# yum install gcc*

6.安装protobuf
6.1下载protocolbuffer
下载地址http://developers.google.com/protocol-buffers/

6.2解压
# tar -zxvf /..目录/protobuf-2.5.0.tar.gz -C /usr/local/protobuf

6.3安装
# cd /usr/local/protobuf/protobuf-2.5.0
# ./configure --prefix=/usr/local/protobuf  --指定安装目录
# make
# make install
# vim /etc/profile
添加以下配置：
export PROTOC_HOME=/usr/local/protobuf
export PATH=$PROTOC_HOME/bin:$PATH
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$PROTOC_HOME/lib
# source /etc/profile

6.4验证是否安装成功
# protoc --version
libprotoc 2.5.0

7.编译hadoop
7.1下载hadoop-2.6.0源码
下载地址http://hadoop.apache.org/

7.2解压
# tar -zxvf /..目录/hadoop-2.6.0-src.tar.gz -C /usr/local/hadoop

7.3编译
# cd /usr/local/hadoop/hadoop-2.6.0-src
# mvn package -Pdist,native -DskipTests -Dtar

8.安装hadoop
8.1在hadoop目录下创建子目录
# cd /usr/lib/hadoop/hadoop-2.6.0
# mkdir tmp
# mkdir name
# mkdir data

8.2配置hadoop-env.sh
# cd /usr/lib/hadoop/hadoop-2.6.0/etc/hadoop
# vim hadoop-env.sh
设置JAVA_HOME和PATH路径
export JAVA_HOME=/usr/lib/java/jdk1.8.0_101
export PATH=$PATH:/usr/lib/hadoop/hadoop-2.6.0/bin
# source hadoop-env.sh
# hadoop version
如果显示以下内容，就表示配置生效了
Hadoop 2.6.0
Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1
Compiled by jenkins on 2014-11-13T21:10Z
Compiled with protoc 2.5.0
From source with checksum 18e43357c8f927c0695f1e9522859d6a
This command was run using /usr/lib/hadoop/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar

8.3配置yarn-env.sh
# cd /usr/lib/hadoop/hadoop-2.6.0/etc/hadoop
# vim yarn-env.sh
设置JAVA_HOME路径
1).先找到以下内容
# some Java parameters
# export JAVA_HOME=/home/y/libexec/jdk1.6.0/
if [ "$JAVA_HOME" != "" ]; then
  #echo "run java in $JAVA_HOME"
  JAVA_HOME=$JAVA_HOME
fi
2).修改第二行配置
export JAVA_HOME=/usr/lib/java/jdk1.8.0_101
# source yarn-env.sh

8.4配置core-site.xml
# cd /usr/lib/hadoop/hadoop-2.6.0/etc/hadoop
# vim core-site.xml
按照如下内容进行配置，fs.default.name的值是hdfs://master:9000
<configuration>
  <property>
    <name>fs.default.name</name>
    <value>hdfs://hadoop1:9000</value>
  </property>

  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://hadoop1:9000</value>
  </property>

  <property>
    <name>io.file.buffer.size</name>
    <value>131072</value>
  </property>

  <property>
    <name>hadoop.tmp.dir</name>
    <value>file:/usr/lib/hadoop/hadoop-2.6.0/tmp</value>
    <description>A base for other temporary directories.</description>
  </property>

  <property>
    <name>hadoop.proxyuser.hduser.hosts</name>
    <value>*</value>
  </property>

  <property>
    <name>hadoop.proxyuser.hduser.groups</name>
    <value>*</value>
  </property>
</configuration>

8.5配置hdfs-site.xml
# cd /usr/lib/hadoop/hadoop-2.6.0/etc/hadoop
# vim hdfs-site.xml
按照如下内容进行配置
<configuration>
  <property>
   <name>dfs.namenode.secondary.http-address</name>
   <value>hadoop1:9001</value>
  </property>

  <property>
   <name>dfs.namenode.name.dir</name>
   <value>file:/usr/lib/hadoop/hadoop-2.6.0/name</value>
  </property>

  <property>
   <name>dfs.datanode.data.dir</name>
   <value>file:/usr/lib/hadoop/hadoop-2.6.0/data</value>
  </property>

  <property>
   <name>dfs.replication</name>
   <value>2</value>
  </property>

  <property>
   <name>dfs.webhdfs.enabled</name>
   <value>true</value>
  </property>
</configuration>

8.6配置mapred-site.xml
# cd /usr/lib/hadoop/hadoop-2.6.0/etc/hadoop
# cp mapred-site.xml.template mapred-site.xml  --默认情况下不存在mapred-site.xml文件，可以从模板拷贝一份
# vim mapred-site.xml
按照如下内容进行配置
<configuration>
  <property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
  </property>

  <property>
    <name>mapreduce.jobhistory.address</name>
    <value>hadoop1:10020</value>
  </property>

  <property>
    <name>mapreduce.jobhistory.webapp.address</name>
    <value>hadoop1:19888</value>
  </property>
</configuration>

8.7配置yarn-site.xml
# cd /usr/lib/hadoop/hadoop-2.6.0/etc/hadoop
# vim yarn-site.xml
按照如下内容进行配置
<configuration>
  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
  </property>

  <property>
    <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
    <value>org.apache.hadoop.mapred.ShuffleHandler</value>
  </property>

  <property>
    <name>yarn.resourcemanager.address</name>
    <value>hadoop1:8032</value>
  </property>

  <property>
    <name>yarn.resourcemanager.scheduler.address</name>
    <value>hadoop1:8030</value>
  </property>

  <property>
    <name>yarn.resourcemanager.resource-tracker.address</name>
    <value>hadoop1:8031</value>
  </property>

  <property>
    <name>yarn.resourcemanager.admin.address</name>
    <value>hadoop1:8033</value>
  </property>

  <property>
    <name>yarn.resourcemanager.webapp.address</name>
    <value>hadoop1:8088</value>
  </property>
</configuration>

8.8配置Slaves文件
# cd /usr/lib/hadoop/hadoop-2.6.0/etc/hadoop
# vim slaves
在文件中添加以下配置
hadoop1
hadoop2

8.9向各节点分发Hadoop程序
# cd /usr/lib/hadoop
# scp -r hadoop-2.6.0 root@hadoop2:/usr/lib/hadoop

9.启动部署
9.1格式化NameNode
# cd /usr/lib/hadoop/hadoop-2.6.0
# ./bin/hdfs namenode -format
16/10/13 11:12:51 INFO common.Storage: Storage directory /usr/lib/hadoop/hadoop-2.6.0/name has been successfully formatted.
16/10/13 11:12:51 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
16/10/13 11:12:51 INFO util.ExitUtil: Exiting with status 0
16/10/13 11:12:51 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at localhost/127.0.0.1
************************************************************/

9.2启动HDFS
# cd /usr/lib/hadoop/hadoop-2.6.0/sbin
# ./start-dfs.sh
# jps --验证HDFS启动，hadoop1上面运行的进程有：NameNode、SecondaryNameNode和DataNode
13315 Jps
11878 DataNode
11753 NameNode
12079 SecondaryNameNode

注意：
1).NameNode启动失败，解决方法：
HDFS把namenode的格式化信息存在了系统的tmp目录下，该目录每次开机都会被清空，因此每次重新启动机器，都需要重新格式化HDFS。

2).DataNode启动失败，要保持name和data的namespaceID、clusterID一致，解决方法：
# cd /usr/lib/hadoop/hadoop-2.6.0/name/current
# vim VERSION
namespaceID=1891453947
clusterID=CID-eb45aa78-5e50-45cb-b6c0-06aa9cd4c476
# cd /usr/lib/hadoop/hadoop-2.6.0/data/current
# vim VERSION
namespaceID=1891453947
clusterID=CID-eb45aa78-5e50-45cb-b6c0-06aa9cd4c476

9.3启动YARN
# cd /usr/lib/hadoop/hadoop-2.6.0/sbin
# ./start-yarn.sh
# jps --验证YARN启动，此时在hadoop1上运行的进程有：NameNode、SecondaryNameNode、DataNode、NodeManager和ResourceManager
14449 Jps
13970 NodeManager
11878 DataNode
11753 NameNode
14121 ResourceManager
12079 SecondaryNameNode

9.4配置环境变量
# vim /etc/profile
在 pathmunge () { 的上方添加以下内容:
export HADOOP_HOME=/usr/lib/hadoop/hadoop-2.6.0
export PATH=.:$HADOOP_HOME/bin:$JAVA_HOME/bin:$PATH
# source /etc/profile

9.5测试
# hadoop version
Hadoop 2.6.0
Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1
Compiled by jenkins on 2014-11-13T21:10Z
Compiled with protoc 2.5.0
From source with checksum 18e43357c8f927c0695f1e9522859d6a
This command was run using /usr/lib/hadoop/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar

1.下载hadoop-2.6.0
下载地址http://hadoop.apache.org/

2.解压
# tar -zxvf /..目录/hadoop-2.6.0.tar.gz -C /usr/lib/hadoop

3.在hadoop目录下创建子目录
# cd /usr/lib/hadoop/hadoop-2.6.0
# mkdir tmp
# mkdir name
# mkdir data

4.配置hadoop-env.sh
# cd /usr/lib/hadoop/hadoop-2.6.0/etc/hadoop
# vim hadoop-env.sh
设置JAVA_HOME和PATH路径
export JAVA_HOME=/usr/lib/java/jdk1.8.0_101
export PATH=$PATH:/usr/lib/hadoop/hadoop-2.6.0/bin
# source hadoop-env.sh
# hadoop version
如果显示以下内容，就表示配置生效了
Hadoop 2.6.0
Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1
Compiled by jenkins on 2014-11-13T21:10Z
Compiled with protoc 2.5.0
From source with checksum 18e43357c8f927c0695f1e9522859d6a
This command was run using /usr/lib/hadoop/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar

5.配置yarn-env.sh
# cd /usr/lib/hadoop/hadoop-2.6.0/etc/hadoop
# vim yarn-env.sh
设置JAVA_HOME路径
1).先找到以下内容
# some Java parameters
# export JAVA_HOME=/home/y/libexec/jdk1.6.0/
if [ "$JAVA_HOME" != "" ]; then
  #echo "run java in $JAVA_HOME"
  JAVA_HOME=$JAVA_HOME
fi
2).修改第二行配置
export JAVA_HOME=/usr/lib/java/jdk1.8.0_101
# source yarn-env.sh

6.配置core-site.xml
# cd /usr/lib/hadoop/hadoop-2.6.0/etc/hadoop
# vim core-site.xml
按照如下内容进行配置，fs.default.name的值是hdfs://master:9000
<configuration>

  <property>

    <name>fs.default.name</name>

    <value>hdfs://hadoop1:9000</value>

  </property>

  <property>

    <name>fs.defaultFS</name>

    <value>hdfs://hadoop1:9000</value>

  </property>

  <property>

    <name>io.file.buffer.size</name>

    <value>131072</value>

  </property>

  <property>

    <name>hadoop.tmp.dir</name>

    <value>file:/usr/lib/hadoop/hadoop-2.6.0/tmp</value>

    <description>Abase for other temporary directories.</description>

  </property>

  <property>

    <name>hadoop.proxyuser.hduser.hosts</name>

    <value>*</value>

  </property>

  <property>

    <name>hadoop.proxyuser.hduser.groups</name>

    <value>*</value>

  </property>

</configuration>

7.配置hdfs-site.xml
# cd /usr/lib/hadoop/hadoop-2.6.0/etc/hadoop
# vim hdfs-site.xml
按照如下内容进行配置
<configuration>

  <property>

   <name>dfs.namenode.secondary.http-address</name>

   <value>hadoop1:9001</value>

  </property>

  <property>

   <name>dfs.namenode.name.dir</name>

   <value>file:/usr/lib/hadoop/hadoop-2.6.0/name</value>

  </property>

  <property>

   <name>dfs.datanode.data.dir</name>

   <value>file:/usr/lib/hadoop/hadoop-2.6.0/data</value>

  </property>

  <property>

   <name>dfs.replication</name>

   <value>2</value>

  </property>

  <property>

   <name>dfs.webhdfs.enabled</name>

   <value>true</value>

  </property>

</configuration>

8.配置mapred-site.xml
# cd /usr/lib/hadoop/hadoop-2.6.0/etc/hadoop
# cp mapred-site.xml.template mapred-site.xml  --默认情况下不存在mapred-site.xml文件，可以从模板拷贝一份
# vim mapred-site.xml
按照如下内容进行配置
<configuration>

  <property>

    <name>mapreduce.framework.name</name>

    <value>yarn</value>

  </property>

  <property>

    <name>mapreduce.jobhistory.address</name>

    <value>hadoop1:10020</value>

  </property>

  <property>

    <name>mapreduce.jobhistory.webapp.address</name>

    <value>hadoop1:19888</value>

  </property>

</configuration>

9.配置yarn-site.xml
# cd /usr/lib/hadoop/hadoop-2.6.0/etc/hadoop
# vim yarn-site.xml
按照如下内容进行配置
<configuration>

  <property>

    <name>yarn.nodemanager.aux-services</name>

    <value>mapreduce_shuffle</value>

  </property>

  <property>

    <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>

    <value>org.apache.hadoop.mapred.ShuffleHandler</value>

  </property>

  <property>

    <name>yarn.resourcemanager.address</name>

    <value>hadoop1:8032</value>

  </property>

  <property>

    <name>yarn.resourcemanager.scheduler.address</name>

    <value>hadoop1:8030</value>

  </property>

  <property>

    <name>yarn.resourcemanager.resource-tracker.address</name>

    <value>hadoop1:8031</value>

  </property>

  <property>

    <name>yarn.resourcemanager.admin.address</name>

    <value>hadoop1:8033</value>

  </property>

  <property>

    <name>yarn.resourcemanager.webapp.address</name>

    <value>hadoop1:8088</value>

  </property>

</configuration>

10.配置Slaves文件
# cd /usr/lib/hadoop/hadoop-2.6.0/etc/hadoop
# vim slaves
在文件中添加以下配置
hadoop1
hadoop2

11.向各节点分发Hadoop程序
# cd /usr/lib/hadoop
# scp -r hadoop-2.6.0 root@hadoop2:/usr/lib/hadoop

12.格式化NameNode
# cd /usr/lib/hadoop/hadoop-2.6.0
# ./bin/hdfs namenode -format
16/10/13 11:12:51 INFO common.Storage: Storage directory /usr/lib/hadoop/hadoop-2.6.0/name has been successfully formatted.
16/10/13 11:12:51 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
16/10/13 11:12:51 INFO util.ExitUtil: Exiting with status 0
16/10/13 11:12:51 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at localhost/127.0.0.1
************************************************************/

13.启动HDFS
# cd /usr/lib/hadoop/hadoop-2.6.0/sbin
# ./start-dfs.sh
# jps --验证HDFS启动，hadoop1上面运行的进程有：NameNode、SecondaryNameNode和DataNode
13315 Jps
11878 DataNode
11753 NameNode
12079 SecondaryNameNode

14.启动YARN
# cd /usr/lib/hadoop/hadoop-2.6.0/sbin
# ./start-yarn.sh
# jps --验证YARN启动，此时在hadoop1上运行的进程有：NameNode、SecondaryNameNode、DataNode、NodeManager和ResourceManager
14449 Jps
13970 NodeManager
11878 DataNode
11753 NameNode
14121 ResourceManager
12079 SecondaryNameNode




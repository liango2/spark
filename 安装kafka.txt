1.下载kafka
http://kafka.apache.org/downloads

2.启动zookeeper
--开启一个Terminal
# tar -zxvf kafka_2.11-0.10.1.1.tgz
# cd kafka_2.11-0.10.1.1
# bin/zookeeper-server-start.sh config/zookeeper.properties
# netstat -tlnp|grep 2181
tcp        0      0 :::2181                     :::*                        LISTEN      4448/java           
--说明zookeeper服务已启动，2181是zookeeper的服务端口
# jps
27724 QuorumPeerMain  --zookeeper进程

3.启动kafka
--开启一个Terminal
# bin/kafka-server-start.sh config/server.properties
--如果链接zookeeper超时
--org.I0Itec.zkclient.exception.ZkTimeoutException: Unable to connect to zookeeper server within timeout: 6000
--就尝试修改server.properties里的zookeeper连接串
--把zookeeper.connect=localhsot:2181修改为zookeeper.connect=hostname:2181
# netstat -tlnp|grep 9092
tcp        0      0 :::9092                     :::*                        LISTEN      5695/java   
--说明kafka服务已启动，9092是kafka的服务端口
# jps
27970 Kafka  --kafka进程

4.创建 topic
--开启一个Terminal
# bin/kafka-topics.sh --create --zookeeper hostname:2181 --replication-factor 1 --partitions 1 --topic test
Created topic "test".
--查看创建的topic
# bin/kafka-topics.sh --list --zookeeper hostname:2181
test

5.producer发送消息
# bin/kafka-console-producer.sh --broker-list hostname:9092 --topic test
--先在另一个Terminal中开启consumer
hello
world
--按ctrl+c退出消息发送
# jps
28972 ConsoleProducer  --producer进程


6.consumer接收消息
--开启一个Terminal
# bin/kafka-console-consumer.sh --bootstrap-server hostname:9092 --topic test --from-beginning
--在producer的Terminal中发送消息
hello
world
--按ctrl+c退出消息接收
--这样就可以在一个终端输入消息，另一个终端读取消息
# jps
29977 ConsoleConsumer  --consumer进程

7.设置broker的集群
7.1.拷贝两个server.properties副本
# cp config/server.properties config/server-1.properties
# cp config/server.properties config/server-2.properties

7.2.编辑副本
# cd config
# vim server-1.properties
broker.id=1  --broker.id属性对于每个节点必须是唯一的
#listeners=PLAINTEXT://:9092  --找到listeners配置，在该注释的下一行添加以下配置
listeners=PLAINTEXT://:9093
log.dirs=/tmp/kafka-logs-1  --使用不同的log目录是为了每个节点存储自己的日志文件，不会互相覆盖。

# vim server-2.properties
broker.id=2
listeners=PLAINTEXT://:9094
log.dirs=/tmp/kafka-logs-2

7.3.启动集群节点
# bin/kafka-server-start.sh config/server-1.properties
# bin/kafka-server-start.sh config/server-2.properties

7.4.创建一个新的topic，有1个分区和3个副本
# bin/kafka-topics.sh --create --zookeeper hostname:2181 --replication-factor 3 --partitions 1 --topic my-replicated-topic
Created topic "my-replicated-topic".
--执行describe来观察哪一个集群服务在处理该topic
# bin/kafka-topics.sh --describe --zookeeper hostname:2181 --topic my-replicated-topic
Topic:my-replicated-topic	PartitionCount:1	ReplicationFactor:3	Configs:
	Topic: my-replicated-topic	Partition: 0	Leader: 1	Replicas: 1,2,0	Isr: 1,2,0
--第一行是对所有分区的一个描述，然后每个分区都会对应一行
--leader：负责处理消息的读和写，leader是从所有节点中随机选择的.此时，broker1作为leader
--replicas：列出了所有的副本节点，不管节点是否在服务中.
--isr：是正在服务中的节点.

7.5.向topic发送消息
--发送消息
# bin/kafka-console-producer.sh --broker-list hostname:9092 --topic my-replicated-topic
hello world
my topic

--接收消息
# bin/kafka-console-consumer.sh --bootstrap-server hostname:9092 --topic my-replicated-topic --from-beginning
hello world
my topic

7.6.容错测试
--kill作为leader的broker1
# ps aux | grep server-1.properties
root     30323  0.0  0.1  41984  4608 pts/4    T    14:45   0:00 vim server-1.properties
root     30390  2.2  7.4 2015268 293528 pts/4  Sl   15:00   1:02 /usr/local/java/jdk1.7.0_80/bin/java ... kafka.Kafka config/server-1.properties
root     32589  0.0  0.0   6448   788 pts/6    S+   15:47   0:00 grep server-1.properties
# kill -9 30390
# bin/kafka-topics.sh --describe --zookeeper hostname:2181 --topic my-replicated-topic
Topic:my-replicated-topic	PartitionCount:1	ReplicationFactor:3	Configs:
	Topic: my-replicated-topic	Partition: 0	Leader: 2	Replicas: 1,2,0	Isr: 2,0
--broker2被选作为leader,broker1不再出现在 in-sync 副本列表中
--此时，consumer依然可以接收producer发送的消息

1.设置Host映射文件
# vim /etc/hosts
在文件的末尾添加以下内容
192.168.29.131 hadoop1
192.168.29.132 hadoop2
# service network restart

2.关闭防火墙
# service iptables status --查看防火墙状态
# chkconfig iptables off  --关闭防火墙

3.关闭SElinux
# getenforce
Enforcing
# vim /etc/selinux/config
#SELINUX=enforcing
SELINUX=disabled  --把enforcing改为disabled

4.更新OpenSSL
# yum update openssl

5.修改SSH配置文件
# vim /etc/ssh/sshd_config
开放以下三个配置：
RSAAuthentication yes
PubkeyAuthentication yes
AuthorizedKeysFile .ssh/authorized_keys
# service sshd restart

6.配置SSH无密码登录
1).用root账户登录192.168.29.131
[root@hadoop1 /]# ssh-keygen -t rsa
[root@hadoop1 /]# cd ~  --打开登录帐号的目录
[root@hadoop1 ~]# ls -a --显示隐藏目录
.                .config    .gnome2_private  install.log.syslog  .scala_history
..               .cshrc     .gnote           .local              .ssh
.abrt            .dbus      .gnupg           .mozilla            .tcshrc
anaconda-ks.cfg  Desktop    .gstreamer-0.10  Music               Templates
.bash_history    Documents  .gtk-bookmarks   .nautilus           .themes
.bash_logout     Downloads  .gvfs            .oracle_jre_usage   .thumbnails
.bash_profile    .esd_auth  .ICEauthority    Pictures            Videos
.bashrc          .gconf     .icons           Public              .viminfo
.bashrc~         .gconfd    .imsettings.log  .pulse              .xinputrc
.cache           .gnome2    install.log      .pulse-cookie
[root@hadoop1 ~]# cd .ssh
[root@hadoop1 .ssh]# ls
id_rsa  id_rsa.pub
[root@hadoop1 .ssh]# cp id_rsa.pub authorized_keys_hadoop1 --把公钥命名为authorized_keys_hadoop1
[root@hadoop1 .ssh]# ls
authorized_keys_hadoop1  id_rsa  id_rsa.pub

2).用root账户登录192.168.29.132
[root@hadoop2 /]# ssh-keygen -t rsa
[root@hadoop2 /]# cd ~
[root@hadoop2 ~]# ls -a
[root@hadoop2 ~]# cd .ssh
[root@hadoop2 .ssh]# ls
id_rsa  id_rsa.pub
[root@hadoop2 .ssh]# cp id_rsa.pub authorized_keys_hadoop2 --把公钥命名为authorized_keys_hadoop2
[root@hadoop2 .ssh]# ls
authorized_keys_hadoop2  id_rsa  id_rsa.pub  known_hosts
[root@hadoop2 .ssh]# scp authorized_keys_hadoop2 root@192.168.29.131:/root/.ssh --把hadoop2节点的公钥复制到hadoop1节点的/root/.ssh目录中

3).切换到192.168.29.131
[root@hadoop1 .ssh]# cd /root/.ssh
[root@hadoop1 .ssh]# ls
authorized_keys_hadoop1  authorized_keys_hadoop2  id_rsa  id_rsa.pub
[root@hadoop1 .ssh]# cat authorized_keys_hadoop1 >> authorized_keys  --把公钥信息保存到authorized_key文件中
[root@hadoop1 .ssh]# ls
authorized_keys          authorized_keys_hadoop2  id_rsa.pub
[root@hadoop1 .ssh]# cat authorized_keys_hadoop2 >> authorized_keys
[root@hadoop1 .ssh]# scp authorized_keys root@192.168.29.132:/root/.ssh --把authorized_key到hadoop2节点的/root/.ssh目录中
[root@hadoop1 .ssh]# ls
authorized_keys          authorized_keys_hadoop2  id_rsa.pub
authorized_keys_hadoop1  id_rsa                   known_hosts

4).切换到192.168.29.132
[root@hadoop2 .ssh]# cd /root/.ssh
[root@hadoop2 .ssh]# ls
authorized_keys  authorized_keys_hadoop2  id_rsa  id_rsa.pub  known_hosts

5).在各个节点中设置authorized_keys读写权限
# cd /root/.ssh
# chmod 400 authorized_keys

6).测试ssh无密码登录是否生效
ssh连接远程主机时，会检查主机的公钥。如果是第一次该主机，会显示该主机的公钥摘要，提示用户是否信任该主机：
当选择接受，就会将该主机的公钥追加到文件 ~/.ssh/known_hosts 中。当再次连接该主机时，就不会再提示该问题了。 
附加说明：
# ssh -o StrictHostKeyChecking=no|ask|yes  IP地址 --修改ssh对主机的public_key的检查等级
参数说明：
  no，最不安全的级别，如果连接server的key在本地不存在，那么就自动添加到文件中（默认是known_hosts），并且给出一个警告。
  ask，默认的级别，如果连接和key不匹配，给出提示，并拒绝登录。
  yes，最安全的级别，如果连接与key不匹配，就拒绝连接，不会有信息提示。
